# 阿里秋招电话面试 #

2019秋招内推

职位：大数据开发

## 1.毕业时间 ##

## 2.介绍嵌入式设计大赛 ##

## 3.先问对xxx有了解吗 ##

## 4.问专业是什么 ##

## 5.问算法是不是了解 ##

## 6.mapreduce的底层原理、调度  ##

	底层原理：

	<1>文件会被划分成多个inputsplit，每一个InputSplit都会分配一个Mapper任务,Mapper任务的输出存放在缓存中，每个map有一个环形内存缓冲区，用于存储任务的输出。默认大小100MB（io.sort.mb属性），一旦达到阀值0.8(io.sort.spill.percent),一个后台线程就把内容写到(spill)Linux本地磁盘中的指定目录（mapred.local.dir）下的新建的一个溢出写文件。

	<2>写磁盘前，要partition,sort。通过分区，将不同类型的数据分开处理，之后对不同分区的数据进行排序，如果有Combiner，还要对排序后的数据进行combine。等最后记录写完，将全部溢出文件合并为一个分区且排序的文件(归并排序)。

	<3>最后将磁盘中的数据送到Reduce中。Reducer通过Http方式得到输出文件的分区，存到内存或磁盘，排序合并(分组)。然后走Reduce阶段。
	{The framework groups Reducer inputs by keys (since different mappers may have output the same key) in this stage.
	The shuffle and sort phases occur simultaneously; while map-outputs are being fetched they are merged.}

	1.一个key\value pair对执行一个map函数
	2.计数器counter是用来记录job的执行进度和状态的}
	3.map的数据量：由文件大小决定，文件被划分成分片，有几个分片就有几个map任务。
	4.对每个分组后的<key, (list of values)> pair，执行一个reduce函数

	=========================================================================================================

	调度：
		通过yarn来实现，yarn主要包括ResourceManager和NodeManager两个组件。ResourceManager负责为集群资源的管理与调度，
		包括Scheduler和AppllicationManager。Scheduler负责资源分配，有FIFO调度器、Capacity调度器、Fair调度器，AppllicationManager
		接收Application的请求，为其分配第一个Container来运行Application，还有监控Application的运行情况，在遇到失败时重
		启ApplicationMaster运行的Container。NodeManager接收ResourceManger的资源分配请求，分配Container给Application,
		监控并报告Container使用信息给ResourceManager。
								---Scheduler
			----ResourceManager
		yarn					---ApplicationManager
			----NodeManager --container

		FIFO调度器:先按照作业的优先级高低，再按照到达时间的先后选择被执行的作业。(MR1一些阻塞型任务会持续占有资源，使得任务无法进行)
		Capacity调度器:集群有多个队列组成，在每个队列内部，作业根据FIFO（依靠优先级决定）进行调度
		Fair调度器:每个用户公平共享集群能力
		https://blog.csdn.net/jiamigu/article/details/79565351
		https://www.cnblogs.com/gaopeng527/p/4930616.html


	调度流程：
		1.客户端向ResourceManager提交application,并请求一个ApplicationMaster实例
		2.ResourceManager为该应用程序分配第一个Container，并与对应的NodeManager通信，
		  要求它在整个Container中启动应用程序的ApplicationMaster；
		3.ApplicationMaster首先向ResourceManager注册，这样用户可以直接通过ResourceManager
		  查看应用程序的运行状态，然后它将为各个任务申请资源，并监控它的运行状态，直到运行结束，即重复步骤4~7；
		4.ApplicationMaster采用轮询的方式通过RPC协议(resource-request协议)向ResourceManager申请和领取资源
		5.一旦ApplicationMaster申请到资源后，则与对应的NodeManager通信(container-launch-specification)，要求其启动任务；
		6.NodeManager为任务设置好运行环境（包括环境变量、jar包、二进制程序等）后，将任务启动命令写到一个脚本中，
		  并通过运行该脚本启动任务；
		7.各个任务通过某RPC协议(application-specific协议)向ApplicationMaster汇报自己的状态和进度，以让ApplicationMaster
		  随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务。
		  在应用程序运行过程中，用户可以随时通过RPC向ApplicationMaster查询应用程序的当前运行状态；
		8.应用程序运行完成后，ApplicationMaster向ResourceManager注销并关闭自己。

		http://blog.csdn.net/suifeng3051/article/details/49486927
		http://blog.csdn.net/u011007180/article/details/52825687
		https://www.cnblogs.com/meiyuanbao/p/3545929.html

## 7.hdfs的调度、文件系统、工作机制 ##

	调度：???
	文件系统：
		hdfs是分布式的文件系统，采用了主从架构，主要包括namenode、secondrynamenode、datanode节点
			namenode:接收客户端读写请求、管理文件系统的命名空间
				(对文件系统的操作，如打开关闭重命名文件目录，block发送到datanode的策略)
			secondrynamenode:保存NN中对HDFS metadata的信息的备份，并减少NN重启的时间
			datanode:存储client发来的数据块block；执行数据块的读写操作；与namenode保持心跳
				（处理来自客户端的读写请求，在namenode调度下block的创建删除复制)

		将文件以block的形式存储在datanode，默认128mb

	工作机制(读写)：

		写数据：
		1.客户端和namenode通信确认是否可以写数据，并返回datanode的位置信息。
		2.客户端将文件划分成块
		3.向第一台datanode传输block，以packet为单位，一个packet为64kb，然后由这台datanode向下面的datanode传输。
		4.当一个block传输完成之后，client再次请求namenode上传第二个block的服务器。
		{packet以chunk为单位进行校验，大小默认为512Byte}

		读数据：
		1.客户端向namenode通信获取block所在的datanode节点,namenode返回给他
		2.客户端根据返回的信息找到相应datanode逐个获取文件的block并在客户端本地进行数据追加合并从而获得整个文件

	https://blog.csdn.net/qq_20641565/article/details/53328279

## 8.jobtrack ##

	对整个集群进行状态监控，任务调度，作业管理。（namenode）
	Tasktracker通过hearbeat机制发送给Jobtracker;执行Jobtrack下达的命令信息。
	包括：启动任务(LaunchTaskAction)、提交任务(CommitTaskAction)、杀死任务

## 9.nn、dn的块的大小，secondrynamenode的作用 ##

	128mb

	secondrynamenode:保存NN中对HDFS metadata的信息的备份，并减少NN重启的时间
		SecondaryNameNode通过HTTP GET方式获取NameNode的fsimage与edits文件；
		合并获取的上述两个文件，产生一个新的fsimage文件；
		SecondaryNameNode用HTTP POST方式发送fsimage.ckpt至NameNode；
		NameNode将fsimage.ckpt与edits.new文件分别重命名为fsimage与edits，然后更新fstime}
		https://blog.csdn.net/WYpersist/article/details/79840776

	{checkpoint过程：
		Namenode上保存着HDFS的命名空间。对于任何对文件系统元数据产生修改的操作，Namenode都会使用EditLog事务日志记录下来。
	    整个文件系统的命名空间，包括数据块到文件的映射、文件的属性等，都存储在FsImage中，EditLog和FsImage放在Namenode所在
		的本地文件系统上。

		当Namenode启动时，它从硬盘中读取Editlog和FsImage，将所有Editlog中的事务作用在内存中的FsImage上，并将这个新版本的
		FsImage从内存中保存到本地磁盘上，然后删除旧的Editlog

		可以通过设置参数dfs.namenode.checkpoint.period周期性checkpoint，或者执行了Editlog中的一部分事务(dfs.namenode.checkpoint.txns)再进行checkpoint
	}


## 10.hadoop如何保证健壮性 ##

	（1）当出现网络分割时，namenode通过心跳包的缺失检测到namenode和datanode失去联系，namenode将该datanode标记成dead,
		那么就不再会向其发送新的IO请求，内部数据不再有效。dead DataNode可能引起一些Block的副本数目低于指定值，NameNode
		不断地跟踪需要复制的Block，并在需要的情况下启动复制。在下列情况中可能需要重新复制：某个DataNode失效、某个副本遭到
		损坏、DataNode上的硬盘错误，或者文件的replication因子增大。
	（2）集群均衡。如果某个DataNode上的空闲空间低于特定的临界点，那么就会自动将数据从一个DataNode搬移到空闲的DataNode。
	（3）从某个datanode获取的block时损坏的，那么会再从其他datanode获取该块的副本。如何检测出时损坏的？
		因为在客户端创建文件时，会计算文件的每个块的校验和(checksum),并将校验和作为一个单独的隐藏文件保存在同一个HDFS名字
		空间下。当客户端获取文件内容后，它会检验从Datanode获取的数据跟相应的校验和文件中的校验和是否匹配，如果不匹配，客户
		端可以选择从其他Datanode获取该数据块的副本。
	（4）FsImage和Editlog是HDFS的核心数据结构。如果这些文件损坏了，整个HDFS实例都将失效。因而，Namenode可以配置成支持维护
		多个FsImage和Editlog的副本。任何对FsImage或者Editlog的修改，都将同步到它们的副本上。
	（5）快照。快照支持某一特定时刻的数据的复制备份。利用快照，可以让HDFS在数据损坏时恢复到过去一个已知正确的时间点。

## 11.zookeeper有了解吗 ##


	zxid：ZooKeeper状态的每一次改变, 都对应着一个递增的Transaction id, 该id称为zxid. 由于zxid的递增性质,
		 如果zxid1小于zxid2, 那么zxid1肯定先于zxid2发生. 创建任意节点, 或者更新任意节点的数据, 或者删除任意节点,
		 都会导致Zookeeper状态发生改变, 从而导致zxid的值增加.

	https://blog.csdn.net/weijifeng_/article/details/79775738
	https://segmentfault.com/a/1190000014479433#articleHeader22

## 12.本硕是不是都是计算机 ##

## 13.操作系统级别的算法有了解吗，拜占庭问题。。。 ##

	https://blog.csdn.net/tingfeng96/article/details/52202048

## 14.spark和storm的区别 ##

	1.spark是批处理、storm是实时处理。spark执行流计算的库是spark streaming，它是对一个时间段内的数据收集起来，作为一个RDD，再处理。
	2.storm的实时性比spark高，吞吐量低。
	3.storm可动态调整并行度。
		storm rebalance topology-name [-w wait-time-secs] [-n new-num-workers] [-e component=parallelism]*
	4.可扩展性好。Spark Streaming可以和Spark Core、Spark SQL无缝整合，也就意味着，我们可以对实时处理出来的中间数据，立即在程序中无缝进行延迟批
	  处理、交互式查询等操作。这个特点大大增强了Spark Streaming的优势和功能。  

## 15.storm都从哪输入 ##

	mysql
	kafka
	JMS
	本地文件系统

	kafka:
		BrokerHosts hosts = new ZkHosts(zkConnString);
		SpoutConfig spoutConfig = new SpoutConfig(hosts, topicName, "/" + topicName, UUID.randomUUID().toString());
		spoutConfig.scheme = new SchemeAsMultiScheme(new StringScheme());
		KafkaSpout kafkaSpout = new KafkaSpout(spoutConfig);

	MySQL：
		public void nextTuple() {
	        String str = "";
	        try {
	            if (res.next()) {
	                String username = res.getString(1);
	                String school = res.getString(2);
	                String device = res.getString(3);
	                String logintime = res.getString(4);
	                str += username+"\t"+school+"\t"+logintime+"\t"+device;
	                collector.emit(new Values(str));
	            }
	        } catch (SQLException e) {
	            e.printStackTrace();
	        }
	    }

	    public void open(Map arg0, TopologyContext topology, SpoutOutputCollector collector) {

	        try {
	            String driver = "com.mysql.jdbc.Driver";
	            Class.forName(driver);
	            Connection conn = DriverManager.getConnection("jdbc:mysql://192.168.1.177:3306/bigdata", "root", "chineseall");
	            sta = conn.createStatement();
	            res = sta.executeQuery("select username,school,devicetype,logintime from device_log");
	        } catch (SQLException e) {
	            e.printStackTrace();
	        } catch (ClassNotFoundException e) {
	            e.printStackTrace();
	        }

	        this.collector = collector;
	    }


## 16.storm的节点 ##

	nimbus:分布代码，提交分配任务，监控集群。
	supervisor:接收任务，分配给worker进程处理，管理worker进程
	zookeeper:负责Nimbus节点和Supervisor节点之间的协调工作，存放集群元数据(心跳信息、配置信息)，
			  nimbus将分配给supervisor的任务写入zookeeper。

## 17.storm构成一个图的节点，可以上游的bolt输出到下游的两个bolt中吗 ##

	可以。
	相同tuple发送到不同的bolt。在setBolt中的grouping中设置的相同的上游的名字
	不同tuple发送到不同的bolt。在发送时指定两次，接受消息时，需要判断数据流
	https://github.com/alibaba/jstorm/blob/49d834764d3c638dac3a939c800aed23484a41e8/docs/jstorm-doc/backup/advance_cn/split_merge_cn.md

## 18.storm防止进入有向无环图？？？？ ##

## 19.spark每个批次处理的数据量 ##

## 20.在公司使用spark处理什么问题 ##

## 21.有没有做过逻辑复杂的例子 ##

## 22.推荐：相似性度量（不同的应用场景） ##

	1.欧式距离：
	2.皮尔逊系数：它在数据不是很规范的时候，会倾向于给出更好的结果。
	3.余弦距离
	4.曼哈顿距离
	5.切比雪夫距离
	7.闵可夫斯基距离
	8.马氏距离
		优点：它不受量纲的影响，两点之间的马氏距离与原始数据的测量单位无关。		
			 它考虑到各种特性之间的联系（例如：一条关于身高的信息会带来一条关于体重的信息，因为两者是有关联的）并且是尺度无关的，即独立于测量尺度）；
			 由标准化数据和中心化数据(即原始数据与均值之差）计算出的二点之间的马氏距离相同。马氏距离还可以排除变量之间的相关性的干扰。
		缺点：夸大了变化微小的变量的作用。受协方差矩阵不稳定的影响，马氏距离并不总是能顺利计算出。

## 23.数据仓库的架构分层 ##

![](https://i.imgur.com/ZdCUN3x.png)

	数据仓库的基本架构主要包含的是数据流入流出的过程，可以分为三层——源数据、数据仓库、数据应用
	源数据：日志关系型数据库，并通过Flume、Sqoop、Kettle等etl工具导入到HDFS，并映射到HIVE的数据仓库表中。
	数据仓库：数据聚合、不同维度的分析、业务分析
	数据应用：报表展示、数据分析、数据挖掘、即席查询

	https://blog.csdn.net/qq_26562641/article/details/54943584

## 24.做的项目偏哪些方面，要具体介绍(网站分析都是分析哪些，出租车都是处理哪些数据)（更侧重数据的格式） ##

## 25.未来的规划，从事的领域 ##

	基于公司的平台，多向同事学习，深入大数据开发领域

## 26.大数据工具有没有系统的学习，有没有看过哪些网站书，最近在看什么书网站 ##

## 27.你还有什么问题 ##
