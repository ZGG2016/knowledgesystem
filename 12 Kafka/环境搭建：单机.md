# 环境搭建：单机

前提要先安装jdk、安装zookeeper

### 下载、解压、重命名

	wget http://mirrors.hust.edu.cn/apache/kafka/1.0.0/kafka_2.11-1.0.0.tgz
	tar -zxvf kafka_2.11-1.0.0.tgz
	mv kafka_2.11-1.0.0 kafka

### 启动

	//启动zookeeper
	zkServer.sh start
	//启动kafka
	bin/kafka-server-start.sh config/server.properties >logs/kafka.log 2>1 &

![](https://i.imgur.com/aph1OHv.png)

![](https://i.imgur.com/6hmijjY.png)

### 创建topic

创建一个名为mytopic的topic

	bin/kafka-topics.sh --create --zookeeper hadoop:2181 --replication-factor 1 --partitions 1 --topic mytopic
	// --replication-factor副本数
    // --partitions 1 分区数

列出所有的topic

	bin/kafka-topics.sh --list --zookeeper hadoop:2181

![](https://i.imgur.com/wl8B0HO.png)

当你在客户端往不存在的topic中发送数据时，kafka会自动创建。

### 发送消息

kafka提供了命令行工具，可以从文件或标准输入中得到输入。封装成消息发送到集群中。默认情况下，一行发送一条消息。

	bin/kafka-console-producer.sh --broker-list hadoop:9092 --topic mytopic
	>This is a message
	>This is another message

![](https://i.imgur.com/Z4ko5UN.png)

### 消费消息

kafka也提供消费者命令行，读取消息，在标准输出上显示。

	bin/kafka-console-consumer.sh --bootstrap-server hadoop:9092 --topic mytopic --from-beginning

![](https://i.imgur.com/I2r6QK7.png)

### 设置多个broker

之前我们只是在单个broker中运行，下面我们扩展集群到3个节点。

首先复制配置文件

	cp config/server.properties config/server-1.properties
    cp config/server.properties config/server-2.properties

编辑配置文件

	config/server-1.properties:
	    broker.id=1
	    listeners=PLAINTEXT://:9093
	    log.dir=/tmp/kafka-logs-1
 
	config/server-2.properties:
	    broker.id=2
	    listeners=PLAINTEXT://:9094
	    log.dir=/tmp/kafka-logs-2

broker.id为集群中节点唯一的持久性的名字。我们必须重载端口和log目录。因为我们现在在同一台机器上运行。要防止broker在同一端口上注册和覆盖对方的数据。

我们已经启动了zookeeper和单节点，现在只需要启动两个新的节点。

	bin/kafka-server-start.sh config/server-1.properties >logs/kafka.log 2>1 &
    bin/kafka-server-start.sh config/server-2.properties >logs/kafka.log 2>1 &

现在创建一个新的topic，具有3个副本

	bin/kafka-topics.sh --create --zookeeper hadoop:2181 --replication-factor 3 --partitions 1 --topic my-replicated-topic

使用“describe topics”命令来查看topic的信息

	> bin/kafka-topics.sh --describe --zookeeper hadoop:2181 --topic my-replicated-topic
	Topic:my-replicated-topic   PartitionCount:1    ReplicationFactor:3 Configs:
    Topic: my-replicated-topic  Partition: 0    Leader: 1   Replicas: 1,2,0 Isr: 1,2,0

第一行给出了所有分区的概要信息，其余的每一行给出了一个分区的信息。这个例子中只有一个分区，所以只有一行。

* "leader":负责所有读写请求。每一个节点都可能会是一个leader。
* "replicas":包含某一分区的节点的列表。
* "isr":备份节点的集合，也就是活着的节点集合。

查看一下刚开始创建的topic的信息

	>bin/kafka-topics.sh --describe --zookeeper hadoop:2181 --topic mytopic
	Topic:mytopic  PartitionCount:1    ReplicationFactor:1 Configs:
    Topic: mytopic Partition: 0    Leader: 0   Replicas: 0 Isr: 0

往新创建的topic中发布一些消息

	> bin/kafka-console-producer.sh --broker-list hadoop:9092 --topic my-replicated-topic
	...
	my test message 1
	my test message 2

消费消息

	> bin/kafka-console-consumer.sh --bootstrap-server hadoop:9092 --from-beginning --topic my-replicated-topic
	...
	my test message 1
	my test message 2

测试集群的容错，kill掉leader，Broker1作为当前的leader，也就是kill掉Broker1。

	> ps aux | grep server-1.properties
	7564 ttys002    0:15.91 /System/Library/Frameworks/JavaVM.framework/Versions/1.8/Home/bin/java...
	> kill -9 7564

其中的节点成为新的leader，而broker1已经不在同步备份集合里了。 

	> bin/kafka-topics.sh --describe --zookeeper hadoop:2181 --topic my-replicated-topic
	Topic:my-replicated-topic   PartitionCount:1    ReplicationFactor:3 Configs:
    Topic: my-replicated-topic  Partition: 0    Leader: 2   Replicas: 1,2,0 Isr: 2,0

但是消息仍然可用

	> bin/kafka-console-consumer.sh --bootstrap-server hadoop:9092 --from-beginning --topic my-replicated-topic
	...
	my test message 1
	my test message 2