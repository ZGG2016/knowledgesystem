# 恒润别人面经 #

## 工作时间多长了? ##

	有过两段实习经历。2017年7月到2018年2月在北京新大陆教育公司做大数据实习生。
	2018年4月到2018年6月在北京医渡云做数据挖掘实习生。

	离职原因：1.因为公司教育相关的，主要是大数据课程和大数据案例开发，学的深度
				有限。部门人员不足。
			 2.因为以后要会成都发展，秋招也即将开始，所以就离职回成都了。

## 做的项目有哪些? ##

	在新大陆的时候，主要做了基于用户的电影推荐系统、芝加哥出租车行驶记录数据分析系统、
	访问E学堂的IP地址实时分析系统，还有一些其他类似但应用场景不同的案例。

	在医渡云，由于公司是做医疗大数据，所以项目主要是专病数据流的开发。完成了山东肿瘤医院食管癌项目
	和天津血研所淋巴瘤项目。

## 讲一下你的项目最有突出的一个? ##

	最突出的应该是基于用户的电影推荐系统。这个项目是基于用户的协同过滤算法在mapreduce的实现，整体架构是
	mapreduce处理数据，mysql存储数据，django和echarts可视化展示数据。

## 都会什么技术,讲一下? ##

	hadoop、spark，hive、flume、kafka了解，其他的技术学过。

## 目前的大数据市场行情? ##

	大数据行业的发展一直上升趋势，未来还会持续上升。现在大数据的应用更具行业化，比如医疗大数据、教育大数据。
	而且大数据技术是深度学习、人工智能的基础。职业有大数据开发、大数据分析、数据挖掘，还有一些具体例如hadoop开发工程师等。

## 大数据的技术最流行的框架? ##

	存储：hdfs
	查询：hbase、hive、impala、presto、kylin
	离线计算：mapreduce、spark
	实时计算：spark streaming、storm、flink、kafka streaming
	调度：zookeeper
	资源管理：yarn、mesos
	消息中间件：kafka
	数据采集:flume、logstash
	搜索：ES(Elasticsearch)
	传输：sqoop
	机器学习：mahout、spark ml、weka
	工作流调度系统:ooize、azkaban

## 哪一种框架最有优点最多? ##

	spark，既可以实时计算，也可以离线计算，提供了spark sql(进行结构化数据的处理)、spark ml、
	spark R(R语言API)和spark graphx(图计算和图挖掘)


## 技术选型的话,用什么框架最好? ##

	spark+hive

## hadoop原理是什么? ##

	主要包括3个模块，用于存储的hdfs，用于数据处理的mapreduce，用于资源调度的yarn

	hdfs包括namenode、datanode、secondrynamenode。
			namenode：管理集群的整个命名空间，维护着文件系统树(filesystem tree)以及
					文件树中所有的文件和文件夹的元数据，处理客户端的读写请求。
			datanode：存储数据，并向namenode发送心跳。
			secondrynamenode：namenode上的元数据的备份

	yarn包括ResourceManager、NodeManager
			ResourceManager：负责集群资源的调度
			NodeManager：接收resourceManager的资源分配请求，分配具体的container给应用，监控并报告Container使用信息给ResourceManager。

	mapreduce执行过程：
		
		<1>文件会被划分成多个inputsplit，每一个InputSplit都会分配一个Mapper任务,Mapper任务的输出存放在缓存中，每个map有一个环形内存缓冲区，用于存储任务的输出。默认大小100MB（io.sort.mb属性），一旦达到阀值0.8(io.sort.spil l.percent),一个后台线程就把内容写到(spill)Linux本地磁盘中的指定目录（mapred.local.dir）下的新建的一个溢出写文件。
	
	　　<2>写磁盘前，要partition,sort。通过分区，将不同类型的数据分开处理，之后对不同分区的数据进行排序，如果有Combiner，还要对排序后的数据进行combine。等最后记录写完，将全部溢出文件合并为一个分区且排序的文件。
	
	　　<3>最后将磁盘中的数据送到Reduce中。Reducer通过Http方式得到输出文件的分区，存到内存或磁盘，排序合并。然后走Reduce阶段。

## spark的具体流程? ##

	1.首先启动sparkcontext，向资源管理器注册申请运行executor资源，资源管理器分配资源并启动executor进程，executor会将运行情况通过
	心跳发送到资源管理器。
	2.sparkcontext构建dag图，将dag图划分成多个stage，dag scheduler将taskset发送到task scheduler,executor向sparkcontext申请task,Task Scheduler将Task发放给Executor运行同时SparkContext将应用程序代码发放给Executor。 
	3.Task在Executor上运行，运行完毕释放所有资源。

![](https://i.imgur.com/2sqwpK8.jpg)

	https://www.cnblogs.com/1130136248wlxk/articles/6289717.html

## storm的提交流程? ##

	客户端编写拓扑，提交到nimbus,主节点查询zookeeper中的从节点的资源信息，确定分发规则(随机分配/轮循分配/hash值固定分配等)，
	开始分配任务，子节点查询zookeeper中的信息，领取任务，分配具体的Worker以及executors执行具体的tasks。 
	每个子节点运行Topology的子集，且整个Storm集群初始化后不会停止，连续运行，直到受到kill相应的守护进程。

	https://blog.csdn.net/licw_0909/article/details/54564761

## kafka的原理? ##

	1.kafka是一种分布式发布-订阅式消息系统。
	2.主要包含topic、producer、consumer和broker四个组件。
		topic是特定类型的消息流，就是kafka对消息进行分类，一类是一个topic。
		producer是发布消息的对象
		consumer是订阅处理消息的对象
		broker是kafka集群中服务器，已发布的消息保存在broker中，消费者从broker中拉数据

	3.生产者将数据生产出来，push到 broker 进行存储，消费者需要消费数据了，就从broker中去pull出数据来，
		然后完成一系列对数据的处理操作。三者通过 zookeeper管理协调(Kafka将元数据信息保存在Zookeeper中)
			https://blog.csdn.net/dly1580854879/article/details/71403778
			https://www.jianshu.com/p/8a61bb2a9219

## flume的原理? ## 

	1.什么是flume?  flume是分布式的可靠、高可用的日志采集、传输、聚合系统。
	2.flume传输数据的基本单元是event.
	3.flume包含source、channel和sink3个组件，source捕获event，然后Source会把event推入(单个或多个)Channel中。
	  channel保存事件，直到事件被sink消费。sink负责持久化日志或者把事件推向另一个Source。
	4.Source消费从外部流进的Events，如AvroSource接收外部客户端传来的或是从别的agent流出来的Avro Event。
	  Source可以把event送往一个或多个channel。channel是一个队列，持有event等待sink来消费，一种Channel
	  的实现：FileChannel使用本地文件系统来作为它的存储。Sink的作用是把Event从channel里移除，送往外部数
	  据仓库或给下一站agent的Source，如HDFSEventSink送往HDFS。同个agent下的source和sink是异步的。
	5.还有多agent模式，即上一层的sink发送event到下一层的source。
		多对一模式，即多个agent的sink发送event到下一层的source。
		一对多模式，即一个agent的多个sink分别发送到不同的目的地，比如hdfs,file、下一个source

	====================================================================================
	source：source组件是专门用来收集数据的，可以处理各种类型、各种格式的日志数据,
			包括avro、thrift、exec、jms、spooling directory、netcat、sequence generator、
			syslog、http、legacy、自定义。
	channel：source组件把数据收集来以后，临时存放在channel中，即channel组件在agent中是
			专门用来存放临时数据的——对采集到的数据进行简单的缓存，可以存放在memory、jdbc、file等等。
	sink：sink组件是用于把数据发送到目的地的组件，目的地包括hdfs、logger、avro、thrift、ipc、
			file、null、hbase、solr、自定义。

	flume的可靠性 
		当节点出现故障时，日志能够被传送到其他节点上而不会丢失。Flume提供了三种级别的可靠性保障，
		从强到弱依次分别为：
			1.end-to-end收到数据agent首先将event写到磁盘上，当数据传送成功后，再删除；
				如果数据发送失败，可以重新发送。
			2.Store on failure（这也是scribe采用的策略，当数据接收方crash时，将
　　　　			数据写到本地，待恢复后，继续发送），
			3.Besteffort（数据发送到接收方后，不会进行确认）。

## hdfs的存储原理? ##

	写数据：
		1.客户端和namenode通信确认是否可以写数据，并返回datanode的位置信息。
		2.客户端将文件划分
		3.向第一台datanode传输block，以packet为单位，一个packet为64kb，然后由这台datanode向下面的datanode传输。
		4.当一个block传输完成之后，client再次请求namenode上传第二个block的服务器。

	读数据：
		1.客户端向namenode通信获取block所在的datanode节点,namenode返回给他
		2.客户端根据返回的信息找到相应datanode逐个获取文件的block并在客户端本地进行数据追加合并从而获得整个文件

## spark的优点? ##

	1.处理速度快。基于内存的计算。
	2.通用性。提供了批处理、交互式查询（通用Spark SQL）、实时流处理（通过Spark Streaming）、
		机器学习（通过Spark MLlib）和图计算
	3.支持多种开发语言
	4.可以在yarn上运行，也可以mesos
	5.计算各种各样的数据源，可以计算hdfs上的、Hbase上的、hive上的数据，kafka和flume上的数据也可以被spark读取，

## kafka消息队列? ##

	消息有两种模式：队列和发布订阅。 在队列模式中，消费者池从服务器读取消息（每个消息只被其中一个读取）
								 发布订阅模式：消息广播给所有的消费者。
	
	通过并行topic的parition —— kafka提供了顺序保证。每个partition仅由同一个
	消费者组中的一个消费者消费到。并确保消费者是该partition的唯一消费者，并按顺序消费数据。

## flume怎么收集数据的? ##

	修改flume-conf.properties文件。
	配置source选项。可以是spool检测目录新增文件；EXEC 执行一个给定的命令获得输出的源；http从远程客户端接收数据。

## flume怎么存储数据的? ##

	使用channel临时存储，可以存放在memory、jdbc、file等等



什么框架最流行?
目前的大数据形式?
 