# 阿里秋招电话面试

2019秋招内推

职位：大数据开发

## 毕业时间

## 介绍嵌入式设计大赛

## 对xxx有了解吗

## 专业是什么

## 算法是不是了解

## mapreduce的底层原理

![mapreduce01](https://s1.ax1x.com/2020/06/22/NGO3ZD.jpg)

	(1)输入文件会被划分成多个inputsplit，每一个InputSplit都会分配一个Map任务，Map任务的输出存放在环形内存缓冲区[默认大小100MB（io.sort.mb属性）]，一旦达到阀值0.8(io.sort.spill.percent)，一个后台线程就把内容写到(spill)本地磁盘中的指定目录（mapred.local.dir）下的新建的一个溢出写文件。

	(2)写磁盘前，要排序、分区。如果有Combiner，对中间过程的输出进行本地的聚集。等最后记录写完，将全部溢出文件合并为一个分区且排序的文件(归并排序)。

	(3)进入Reduce阶段。Reducer通过Http方式得到Map输出文件的分区、存到内存或磁盘、进行归并排序、执行Reduce方法。


## mapreduce的调度

主要有两种调度策略：

（1）容器调度器[Capacity Scheduler]

系统默认。Capacity Scheduler 允许多个组织共享整个集群，每个组织可以获得集群的一部分计算能力。通过为每个组织分配专门的队列，然后再为每个队列分配一定的集群资源，这样整个集群就可以通过设置多个队列的方式给多个组织提供服务了。除此之外，队列内部又可以垂直划分(子队列)，这样一个组织内部的多个成员就可以共享这个队列资源了，在一个队列内部，资源的调度是采用的是先进先出FIFO策略(例如，作业A和作业B被先后提交。那么在执行作业B的任务前，作业A中的所有map任务都应该已经执行完)。

（2）公平调度器[Fair Scheduler]

Fair Scheduler允许应用程序公平共享集群资源的调度器。当只有一个应用程序运行时，该应用程序可以使用整个集群资源，当其他应用程序提交之后，释放一部分资源给新提交的应用程序，所以每个应用程序最终会得到大致相同的资源量。

支持队列和层级队列。Fairscheduler 为队列分配了最小共享份额，这对确保了特定用户、组、产品应用始终获得足够的资源。当队列包含应用程序时，它至少能获得最小共享份额，但是当队列占用的资源有空余时，那么空余的资源会分配给其他运行中的应用程序。这既保证了队列的容量，又可以 在这些队列不包含应用程序时高效的利用资源。

FairScheduler默认让所有应用程序都运行，但也能通过配置文件限制每个用户、队列的运行的应用程序数量。

再详细的话，可以具体讲yarn的执行流程。

## hdfs的调度、文件系统、工作机制

调度：???

文件系统:[hdfs架构]

	HDFS 是分布式文件系统，采用主从架构。一个 HDFS 集群是由一个 Namenode 和一定数目的 Datanodes 组成。

			Namenode 是一个中心服务器，负责管理文件系统的名字空间(namespace)以及接收客户端对文件的访问请求。
			（操作文件系统的名字空间，比如打开、关闭、重命名文件或目录。它也负责确定 blocks 到具体 Datanode 节点的映射）

			Datanode 一般是一个节点一个，负责管理它所在节点上的存储，执行客户端的读写请求。

	一个文件其实被分成一个或多个 blocks，一个block默认128mb，以 blocks 的形式存储在 Datanode 上。在 Namenode 的统一调度下进行 blocks 的创建、删除和复制。

工作机制[读写]：

![hdfs03](https://s1.ax1x.com/2020/06/26/NreRF1.png)

      1、根namenode通信请求上传文件，namenode检查目标文件是否已存在，父目录是否存在
      2、namenode返回是否可以上传
      3、client会先对文件进行切分，比如一个blok块128m，文件有300m就会被切分成3个块，一个128M、一个128M、一个44M请求第一个 block该传输到哪些datanode服务器上
      4、namenode返回datanode的服务器
      5、client请求一台datanode上传数据（本质上是一个RPC调用，建立pipeline），第一个datanode收到请求会继续调用第二个datanode，然后第二个调用第三个datanode，将整个pipeline建立完成，逐级返回客户端
      6、client开始往A上传第一个block（先从磁盘读取数据放到一个本地内存缓存），以packet为单位（一个packet为64kb），当然在写入的时候datanode会进行数据校验，它并不是通过一个packet进行一次校验而是以chunk为单位进行校验（512byte），第一台datanode收到一个packet就会传给第二台，第二台传给第三台；第一台每传一个packet会放入一个应答队列等待应答
      7、当一个block传输完成之后，client再次请求namenode上传第二个block的服务器。

![hdfs04](https://s1.ax1x.com/2020/06/26/NreWJx.png)

      1、跟namenode通信查询元数据（block所在的datanode节点），找到文件块所在的datanode服务器
      2、挑选一台datanode（就近原则，然后随机）服务器，请求建立socket流
      3、datanode开始发送数据（从磁盘里面读取数据放入流，以packet为单位来做校验）
      4、客户端以packet为单位接收，先在本地缓存，然后写入目标文件，后面的block块就相当于是append到前面的block块最后合成最终需要的文件。

## 8 jobtrack

	对整个集群进行状态监控，任务调度，作业管理。（namenode）
	Tasktracker通过hearbeat机制发送给Jobtracker;执行Jobtrack下达的命令信息。
	包括：启动任务(LaunchTaskAction)、提交任务(CommitTaskAction)、杀死任务

## 9 nn、dn的块的大小，secondrynamenode的作用

128mb

NameNode包含了如下两个文件：

    - FsImage - 存储整个文件系统的名字空间，包括数据块到文件的映射、文件系统的属性等。

    - Editlog - 对于任何对文件系统元数据产生修改的操作，都会记录在 Editlog 中。

当 Namenode 启动时，将所有 Editlog 中的事务作用在内存中的 FsImage 上，从而得到一个文件系统的最新快照。但是在产品集群中NameNode是很少重启的，这也意味着当 NameNode 运行了很长时间后，Editlog 文件会变得很大。在这种情况下就会出现下面一些问题：

    - Editlog 文件会变的很大，怎么去管理这个文件是一个挑战。

    - NameNode 的重启会花费很长时间，因为在 Editlog 中有很多改动，要合并到 FsImage 文件上。

    - 如果 NameNode 挂掉了，那我们就丢失了很多改动，因为此时的 FsImage 文件非常旧。

所以，SecondaryNameNode 就是来帮助解决上述问题的，它的职责是合并 NameNode 的 Editlog 到 FsImage 文件中。

![hdfs05](https://s1.ax1x.com/2020/06/26/NrQEsf.jpg)

上图我们看到了Secondary NameNode是怎样工作的。

    - 首先，它定时到NameNode去获取 Editlog，并更新到Secondary NameNode自己的fsimage上。

    - 一旦它有了新的 fsimage 文件，它将其拷贝回 NameNode 中。

    - NameNode 在下次重启时会使用这个新的fsimage文件，从而减少重启的时间。

Secondary NameNode所做的不过是在文件系统中设置一个检查点来辅助NameNode更好的工作。它不是要取代掉NameNode也不是NameNode的备份。所以Secondary NameNode称为检查点节点。

NameNode是什么时候将改动写到 Editlog 中的？

    这个步骤，实际上是由DataNode的写操作触发的，当我们往DataNode写文件时，DataNode会跟NameNode通信，告诉NameNode什么文件的第几个block放在它那里，NameNode这个时候会将这些元数据信息写到 Editlog 文件中。

## 10 hadoop如何保证健壮性

磁盘数据错误，心跳检测和重新复制

每个 Datanode 节点周期性地向 Namenode 发送心跳信号。网络割裂可能导致一部分 Datanode 跟 Namenode 失去联系。Namenode 通过心跳信号的缺失来检测这一情况，并将这些近期不再发送心跳信号 Datanode 标记为宕机，不会再将新的 IO 请求发给它们。任何存储在宕机 Datanode 上的数据将不再有效。**Datanode 的宕机可能会引起一些数据块的副本系数低于指定值，Namenode 不断地检测这些需要复制的数据块，一旦发现就启动复制操作**。在下列情况下，可能需要重新复制：**某个 Datanode 节点失效，某个副本遭到损坏，Datanode 上的硬盘错误，或者文件的副本系数增大**。

保守地说，标记 datanode 为宕机的时间很长(默认超过10分钟)，以避免由于 datanode 的状态变化而导致频繁复制。对于性能敏感的工作负载，用户可以通过设置缩短 datanode 为宕机的时间，并避免将数据读取 和/或 写入宕机的节点。

集群均衡

HDFS 的架构支持 **数据均衡策略**。如果某个 Datanode 节点上的空闲空间低于特定的临界点，按照均衡策略系统就会自动地将数据从这个 Datanode 移动到其他空闲的 Datanode。当对某个文件的请求突然增加，那么就自动创建该文件新的副本，并且同时重新平衡集群中的其他数据。这些均衡策略目前还没有实现。

数据完整性

从某个 Datanode 获取的 block 有可能是损坏的，原因可能是 Datanode 的存储设备错误、网络错误或者软件bug。HDFS 客户端软件实现了对 HDFS 文件内容的 **校验和(checksum)检查。当客户端创建一个新的 HDFS 文件，会计算这个文件每个数据块的校验和，并将校验和作为一个单独的隐藏文件保存在同一个HDFS名字空间下。当客户端获取文件内容后，它会检验从 Datanode 获取的数据 跟相应的校验和文件中的校验和 是否匹配，如果不匹配，客户端可以选择从其他Datanode获取该数据块的副本。**

元数据磁盘错误

FsImage 和 Editlog 是 HDFS 的核心数据结构。如果这些文件损坏了，整个 HDFS 实例都将失效。因而，**Namenode 可以配置成支持维护多个 FsImage 和 Editlog 的副本。任何对 FsImage 或者 Editlog 的修改，都将同步到它们的副本上**。当 Namenode 重启的时候，它会选取最近的完整的 FsImage 和 Editlog 来使用。

提高抗故障弹性另一个的措施就是 **通过设置多个 NameNodes 实现高可用性，要么基于 NFS 实现共享存储，要么使用一个分布式的 Edit log(Journal)。后者是推荐的方法**。

快照

快照支持某一特定时刻的数据的备份。利用快照，可以让 HDFS 在数据损坏时恢复到过去一个已知正确的时间点。

## 11 zookeeper有了解吗


	zxid：ZooKeeper状态的每一次改变, 都对应着一个递增的Transaction id, 该id称为zxid. 由于zxid的递增性质,
		 如果zxid1小于zxid2, 那么zxid1肯定先于zxid2发生. 创建任意节点, 或者更新任意节点的数据, 或者删除任意节点,
		 都会导致Zookeeper状态发生改变, 从而导致zxid的值增加.

	https://blog.csdn.net/weijifeng_/article/details/79775738
	https://segmentfault.com/a/1190000014479433#articleHeader22

## 12 本硕是不是都是计算机

## 13 操作系统级别的算法有了解吗，拜占庭问题。。。

	https://blog.csdn.net/tingfeng96/article/details/52202048

## 14 spark和storm的区别  

	1.spark是批处理、storm是实时处理。spark执行流计算的库是spark streaming，它是对一个时间段内的数据收集起来，作为一个RDD，再处理。
	2.storm的实时性比spark高，吞吐量低。
	3.storm可动态调整并行度。
		storm rebalance topology-name [-w wait-time-secs] [-n new-num-workers] [-e component=parallelism]*
	4.可扩展性好。Spark Streaming可以和Spark Core、Spark SQL无缝整合，也就意味着，我们可以对实时处理出来的中间数据，立即在程序中无缝进行延迟批
	  处理、交互式查询等操作。这个特点大大增强了Spark Streaming的优势和功能。  

## 15 storm都从哪输入

	mysql
	kafka
	JMS
	本地文件系统

	kafka:
		BrokerHosts hosts = new ZkHosts(zkConnString);
		SpoutConfig spoutConfig = new SpoutConfig(hosts, topicName, "/" + topicName, UUID.randomUUID().toString());
		spoutConfig.scheme = new SchemeAsMultiScheme(new StringScheme());
		KafkaSpout kafkaSpout = new KafkaSpout(spoutConfig);

	MySQL：
		public void nextTuple() {
	        String str = "";
	        try {
	            if (res.next()) {
	                String username = res.getString(1);
	                String school = res.getString(2);
	                String device = res.getString(3);
	                String logintime = res.getString(4);
	                str += username+"\t"+school+"\t"+logintime+"\t"+device;
	                collector.emit(new Values(str));
	            }
	        } catch (SQLException e) {
	            e.printStackTrace();
	        }
	    }

	    public void open(Map arg0, TopologyContext topology, SpoutOutputCollector collector) {

	        try {
	            String driver = "com.mysql.jdbc.Driver";
	            Class.forName(driver);
	            Connection conn = DriverManager.getConnection("jdbc:mysql://192.168.1.177:3306/bigdata", "root", "chineseall");
	            sta = conn.createStatement();
	            res = sta.executeQuery("select username,school,devicetype,logintime from device_log");
	        } catch (SQLException e) {
	            e.printStackTrace();
	        } catch (ClassNotFoundException e) {
	            e.printStackTrace();
	        }

	        this.collector = collector;
	    }


## 16 storm的节点

	nimbus:分布代码，提交分配任务，监控集群。
	supervisor:接收任务，分配给worker进程处理，管理worker进程
	zookeeper:负责Nimbus节点和Supervisor节点之间的协调工作，存放集群元数据(心跳信息、配置信息)，
			  nimbus将分配给supervisor的任务写入zookeeper。

## 17 storm构成一个图的节点，可以上游的bolt输出到下游的两个bolt中吗

	可以。
	相同tuple发送到不同的bolt。在setBolt中的grouping中设置的相同的上游的名字
	不同tuple发送到不同的bolt。在发送时指定两次，接受消息时，需要判断数据流
	https://github.com/alibaba/jstorm/blob/49d834764d3c638dac3a939c800aed23484a41e8/docs/jstorm-doc/backup/advance_cn/split_merge_cn.md

## 18 storm防止进入有向无环图？？？？  

## 19 spark每个批次处理的数据量

## 20 在公司使用spark处理什么问题  

## 21 有没有做过逻辑复杂的例子

## 22 推荐：相似性度量（不同的应用场景）

	1.欧式距离：
	2.皮尔逊系数：它在数据不是很规范的时候，会倾向于给出更好的结果。
	3.余弦距离
	4.曼哈顿距离
	5.切比雪夫距离
	7.闵可夫斯基距离
	8.马氏距离
		优点：它不受量纲的影响，两点之间的马氏距离与原始数据的测量单位无关。		
			 它考虑到各种特性之间的联系（例如：一条关于身高的信息会带来一条关于体重的信息，因为两者是有关联的）并且是尺度无关的，即独立于测量尺度）；
			 由标准化数据和中心化数据(即原始数据与均值之差）计算出的二点之间的马氏距离相同。马氏距离还可以排除变量之间的相关性的干扰。
		缺点：夸大了变化微小的变量的作用。受协方差矩阵不稳定的影响，马氏距离并不总是能顺利计算出。

## 23 数据仓库的架构分层

![](https://i.imgur.com/ZdCUN3x.png)

	数据仓库的基本架构主要包含的是数据流入流出的过程，可以分为三层——源数据、数据仓库、数据应用
	源数据：日志关系型数据库，并通过Flume、Sqoop、Kettle等etl工具导入到HDFS，并映射到HIVE的数据仓库表中。
	数据仓库：数据聚合、不同维度的分析、业务分析
	数据应用：报表展示、数据分析、数据挖掘、即席查询

	https://blog.csdn.net/qq_26562641/article/details/54943584

## 24 做的项目偏哪些方面，要具体介绍(网站分析都是分析哪些，出租车都是处理哪些数据)（更侧重数据的格式）

## 25 未来的规划，从事的领域  

	基于公司的平台，多向同事学习，深入大数据开发领域

## 26 大数据工具有没有系统的学习，有没有看过哪些网站书，最近在看什么书网站  

## 27 你还有什么问题
