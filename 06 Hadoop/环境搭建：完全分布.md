# Hadoop完全分布式环境搭建

    机器：3台虚拟机test、test2、test3
    Ip：  192.168.0.6、192.168.0.8、192.168.0.9

(1)建立虚拟机，网络设置为桥接模式。

(2)更改主机名

    执行命令：vi  /etc/hostname
    保存退出（:wq）
    验证：重启：reboot
    执行命令：hostname

(3)主机名和IP绑定，建立各主机间的联系

分别在主机test/test1/test2执行如下步骤：

    执行命令：ifconfig  获取IP地址ping
    执行命令：vi /etc/hosts，增加内容：IP地址  主机名。
    保存退出（:wq）
    验证：执行命令：ping 主机名

![1](https://s1.ax1x.com/2020/05/31/t1jSte.png)

![2](https://s1.ax1x.com/2020/05/31/t1jpfH.png)

![3](https://s1.ax1x.com/2020/05/31/t1Xj0K.png)

![4](https://s1.ax1x.com/2020/05/31/t1XvTO.png)

(4)关防火墙

    执行命令：systemctl stop firewalld.service
    验证：firewall-cmd --state
    禁止firewall开机启动：systemctl disable firewalld.service

![5](https://s1.ax1x.com/2020/05/31/t1vhiF.png)

(5)配置宿主机hosts文件（使宿主机和虚拟机系统可以相互ping通）

C:\Windows\System32\drivers\etc\hosts目录下,添加如下内容：
    192.168.0.6  test
    192.168.0.8  test2
    192.168.0.9  test3
    保存

![6](https://s1.ax1x.com/2020/05/31/t1vRaT.png)

(6)配置SSH，实现节点间的无密码登录

无密码登陆，效果也就是在test上，通过 ssh test2或 ssh test3就可以登陆到对方计算机上。而且不用输入密码。

分别在三台虚拟机的/root目录下执行：

    ssh-keygen -t rsa(设置ssh的密钥和密钥的存放路径。 路径为~/.ssh下。)
    进入到.ssh目录，执行如下命令：cp id_rsa.pub  authorized_keys(将公钥放到authorized_keys里)

将test上的authorized_keys放入其他虚拟机的~/.ssh目录下:

    scp authorized_keys test2:~/.ssh/
    scp authorized_keys test3:~/.ssh/

![7](https://s1.ax1x.com/2020/05/31/t1vWIU.png)

(7)安装JDK

删除/usr/local目录下的所有内容：rm -rf *

对test:

    查看虚拟机版本：getconf LONG_BIT
    下载、解压、重命名jdk
    解压：tar -zxvf  jdk-8u121-linux-x64.tar.gz
    重命名: mv  jdk1.8.0_121  jdk
    配置环境变量：
        vi  /etc/profile
        export JAVA_HOME=/usr/local/jdk（等号两边不能有空格）
        export PATH=.:$JAVA_HOME/bin:$PATH
        使其生效：source /etc/profile
    验证：java -version
    将test的jdk文件发送至test2、test3
        scp -r jdk  test2:/usr/local/
        scp -r jdk  test3:/usr/local/
    配置test2、test3的环境变量
        vi  /etc/profile
        export JAVA_HOME=/usr/local/jdk（等号两边不能有空格;jdk的解压路径）
        使其生效：source /etc/profile
    验证：java -version
   （也可以直接从test复制到test2、test3：scp -r /etc/profile test3:/etc）

 (8)安装Hadoop

对test:

    下载
    解压: tar -zxvf hadoop-2.7.3.tar.gz
    重命名: mv hadoop-2.7.3 hadoop
    设置环境变量:
        vi /etc/profile
        export HADOOP_HOME=/usr/local/hadoop
        export PATH=.:$HADOOP_HOME/bin:$JAVA_HOME/bin:$PATH
        使其生效：source /etc/profile
    配置hadoop配置文件
        在/usr/local/hadoop/etc/hadoop目录下,分别配置文件hadoop-env.sh、core-site.xml、hdfs-site.xml和mapred-site.xml
        注：目录中没有mapred-site.xml文件，需要复制一份目录中的mapred-site.xml.template文件，并重命名为mapred-site.xml。
    修改slaves文件
        文件在在/usr/local/hadoop/etc/hadoop目录下
        更改其内容为：

![8](https://s1.ax1x.com/2020/05/31/t1v2ZV.png)

    将test的hadoop文件发送到test2、test3
        scp -r hadoop  test2:/usr/local/
        scp -r hadoop  test3:/usr/local/
          （要删除各个从节点dfs目录下的data目录）
    配置test2、test3的环境变量
        scp -r /etc/profile test2:/etc
        scp -r /etc/profile test3:/etc
    分别：source /etc/profile
    （注：对hadoop配置熟练的话，可以把jdk，hadoop一起配置）

(9)格式化并启动

    对test:
    bin/hdfs namenode -format
    sbin/start-all.sh
    启动后，分别在test/test2/test3输入jps查看进程

![9](https://s1.ax1x.com/2020/05/31/t1vcq0.png)

![10](https://s1.ax1x.com/2020/05/31/t1v4G4.png)

(10)在浏览器输入： test:50070、test:8088

![11](https://s1.ax1x.com/2020/05/31/t1v5RJ.png)

![12](https://s1.ax1x.com/2020/05/31/t1vIz9.png)

![13](https://s1.ax1x.com/2020/05/31/t1vTMR.png)


### 2 配置文件

注：添加配置文件的时候，去掉下面的注释

    1.hadoop-env.sh
    export JAVA_HOME=/usr/local/jdk/

==============================================

    2.core-site.xml
    <configuration>
      <property>
      <!-- 指定namenode的hdfs协议的文件系统通信地址 -->  
            <name>fs.defaultFS</name>  
            <value>hdfs://test:9000</value>  
      </property>
      <property>
      <!-- 用来执行文件IO缓冲区的大小.该属性值单位为KB，131072KB即为默认的64M -->
             <name>io.file.buffer.size</name>
             <value>131072</value>	 
      </property>
      <property>
      <!--  指定hadoop临时目录 -->
            <name>hadoop.tmp.dir</name>
            <value>/usr/local/hadoop/tmp</value>
        </property>   
    </configuration>

==============================================

    3.hdfs-site.xml
    <configuration>
        <property>  
            <name>dfs.namenode.name.dir</name>  
            <value>/usr/local/hadoop/dfs/name</value>  
        </property>  
        <property>  
        <!-- datanode数据的存放地点。也就是block块存放的目录了-->
            <name>dfs.datanode.data.dir</name>  
            <value>/usr/local/hadoop/dfs/data</value>  
         </property>  
         <property>
         <!-- hdfs的副本数设置。也就是上传一个文件，其分割为block块后，每个block的冗余副本个数-->
            <name>dfs.replication</name>  
            <value>1</value>  
         </property>  
         <property>
         <!-- 开启hdfs的web访问接口。默认端口是50070-->  
            <name>dfs.webhdfs.enabled</name>  
            <value>true</value>  
         </property>
     	<property>
            <name>dfs.permissions</name>
            <value>false</value>
        </property>
    </configuration>

==============================================

    4.mapred-site.xml
    <configuration>
         <property>
         <!---- 指定mapreduce框架为yarn方式 -->
    	<name>mapreduce.framework.name</name>
    	<value>yarn</value>
          </property>  
          <property>
          <!---- 指定mapreduce框架jobhistory的内部通讯地址。-->
                <name>mapreduce.jobhistory.address</name>  
                <value>test:10020</value>  
           </property>  
           <property>  
           <!---- 指定mapreduce框架web查看的地址 -->
                <name>mapreduce.jobhistory.webapp.address</name>  
                <value>test:19888</value>  
           </property>

    </configuration>

==============================================

    5.yarn-site.xml

    <configuration>

    <!-- Site specific YARN configuration properties -->
         <property>
         <!---- NodeManager上运行的附属服务 -->
              <name>yarn.nodemanager.aux-services</name>  
              <value>mapreduce_shuffle</value>  
         </property>  
         <property>                                                                  
              <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>  
              <value>org.apache.hadoop.mapred.ShuffleHandler</value>  
         </property>  
         <property>
         <!--- 客户端对ResourceManager主机通过 host:port 提交作业 -->  
              <name>yarn.resourcemanager.address</name>  
              <value>test:8032</value>  
         </property>  
         <property>
         <!--- ApplicationMasters 通过ResourceManager主机访问host:port跟踪调度程序获资源 -->  
              <name>yarn.resourcemanager.scheduler.address</name>  
              <value>test:8030</value>  
         </property>  
         <property>
          <!--- NodeManagers通过ResourceManager主机访问host:port -->   
              <name>yarn.resourcemanager.resource-tracker.address</name>  
              <value>test:8031</value>  
         </property>  
         <property>
         <!--- 管理命令通过ResourceManager主机访问host:port -->    
              <name>yarn.resourcemanager.admin.address</name>  
              <value>test:8033</value>  
         </property>  
         <property>
         <!--- ResourceManager web页面 -->   
              <name>yarn.resourcemanager.webapp.address</name>  
              <value>test:8088</value>  
         </property>  
    </configuration>
